"""
Evaluator constructor
"""

"""
Imports
"""
import numpy as np
import pandas as pd
import copy
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics.pairwise import cosine_similarity

class Evaluator:
    """
    Class that evaluates the perturbations created in terms of their explainability metrics
    """
    def __init__(self, data_obj, perturbator_obj, x_iterations) -> None:
        
        self.regul = perturbator_obj.regul
        self.name = data_obj.name
        self.ord_scaler, self.con_scaler = data_obj.ord_scaler, data_obj.con_scaler
        self.x_iterations = x_iterations
        self.features = perturbator_obj.features
        self.ordinal = perturbator_obj.ordinal
        self.processed_features = perturbator_obj.processed_features
        self.bin_enc_cols = perturbator_obj.bin_enc_cols
        self.cat_enc_cols = perturbator_obj.cat_enc_cols
        self.idx_cat_cols_dict = perturbator_obj.idx_cat_cols_dict
        self.global_model = perturbator_obj.global_model
        self.perturbator_type = perturbator_obj.type
        self.perturbator_ioi_dict = perturbator_obj.ioi_dict
        self.lin_model_dict, self.accuracy_dict, self.fidelity_ratio_dict, self.feat_robustness_dict, self.feasibility_ratio_dict, self.exec_time_dict = self.performance(data_obj, perturbator_obj)
        
    def coefficient_accuracy(self, data, lin_model, ioi):
        """
        Method that calculates the feature coefficient accuracy between the linear and the global model
        Input lin_model: Local linear model trained on the perturbations obtained
        Input data: data object
        Input lin_model: Linear model
        Input true_expl_x: Instance of Interest object
        Output coefficient_acc: The accuracy coefficient as measured by the cosine similarity between either ground truth or global linear model
        """
        linear_model_coef = lin_model.coef_
        if ioi.true_expl_x is None:
            global_model_coef = self.global_model.call_coefficients(ioi,data.processed_train_pd,data.train_target)
        else:
            global_model_coef = ioi.true_expl_x
        coefficient_acc = cosine_similarity(global_model_coef, linear_model_coef)
        return coefficient_acc[0][0]
    
    def fidelity(self, lin_model, processed_perturbations, perturbations_labels):
        """
        Method that calculates the fidelity of the local model w.r.t. the predicted labels
        Output fidelity_ratio: The fidelity ratio between the global or ground truth labels and the local linear labels
        """
        linear_prediction_label = lin_model.predict(processed_perturbations)
        verification_labels = linear_prediction_label == perturbations_labels
        fidelity_ratio = np.sum(verification_labels)/len(linear_prediction_label)
        return fidelity_ratio

    def robustness(self, perturbator_obj, data_obj, ioi, ioi_label):
        """
        Method that calculates the robustness of the perturbations generated by the perturbator object on the described iterations on x
        Input perturbator: Perturbator object
        Input ioi: IOI object
        Input ioi_label: Label of the instance of interest
        Output mean_lin_coefficients_cv: Mean absolute variation coefficient among different iterations of the local explainer algorithm
        """
        lin_coefficients_list = []
        for i in range(self.x_iterations):
            # print(f'Robustness Analysis, Iteration: {i}')
            seed_random_sel = np.random.randint(1,10000,1)
            perturbations, processed_perturbations, pert_weights, some_exec_time = perturbator_obj.perturbation_function(ioi, data_obj, ioi_label, seed_sel = seed_random_sel, robustness_call = True)
            perturbations_labels = perturbator_obj.perturbation_target(processed_perturbations)
            lin_model_i = RidgeClassifier(alpha=self.regul)
            lin_model_i.fit(processed_perturbations,perturbations_labels,sample_weight=pert_weights.reshape(perturbations_labels.shape))
            linear_model_coef = lin_model_i.coef_
            lin_coefficients_list.append(linear_model_coef)
        lin_coefficients_mean_feat = np.abs(np.mean(lin_coefficients_list,axis=0))
        lin_coefficients_std_feat = np.std(lin_coefficients_list,axis=0,ddof=1)
        lin_coefficients_mean_feat_denom = np.copy(lin_coefficients_mean_feat)
        lin_coefficients_mean_feat_denom[np.abs(lin_coefficients_mean_feat_denom) < 1] = 1
        lin_coefficients_cv = lin_coefficients_std_feat / lin_coefficients_mean_feat
        mean_lin_coefficients_cv = np.mean(lin_coefficients_cv)
        return mean_lin_coefficients_cv

    def feasibility(self, processed_perturbations):
        """
        Method that indicates whether cf is a feasible counterfactual with respect to x and the feature mutability
        Input perturbator: Perturbator object
        Output feasibility_ratio: The ratio of feasible instances w.r.t. the total number of instances generated in the neighborhood
        """
        toler = 0.000001
        if len(self.ordinal) > 0: 
            feat_step_ord = pd.Series(data=1/(self.ord_scaler.data_max_ - self.ord_scaler.data_min_),index=[i for i in self.features if i in self.ordinal])
        feasible_counter = 0
        for i in range(processed_perturbations.shape[0]):
            pert_i = processed_perturbations[i,:]
            feasibility = True
            for j in range(len(self.processed_features)):
                feat_j = self.processed_features[j]
                if feat_j in self.bin_enc_cols:
                    if not np.isclose(pert_i[j],[0,1],atol=toler).any():
                        feasibility = False
                        break
                elif feat_j in self.cat_enc_cols:
                    if not np.isclose(pert_i[j],[0,1],atol=toler).any():
                        same_cat_idx = self.idx_cat_cols_dict[feat_j[:-2]]
                        if not np.isclose(np.sum(pert_i[same_cat_idx]),1,atol=toler):
                            feasibility = False
                            break
                elif feat_j in self.ordinal:
                    possible_val = np.linspace(0,1,int(1/feat_step_ord[feat_j]+1),endpoint=True)
                    if not np.isclose(pert_i[j],possible_val,atol=toler).any():
                        feasibility = False
                        break
                else:
                    if pert_i[j] < 0-toler or pert_i[j] > 1+toler:
                        feasibility = False
                        break
            if feasibility:
                feasible_counter += 1
        feasibility_ratio = feasible_counter/len(processed_perturbations)
        return feasibility_ratio
    
    def performance(self, data_obj, perturbator_obj):
        """
        Method that adds a perturbator performance metrics set to the evaluator
        Input data_obj: data object
        Input perturbator_obj: perturbator object
        """
        ioi_dict = perturbator_obj.ioi_dict
        lin_model_dict, accuracy_dict, fidelity_ratio_dict, feat_robustness_dict, feasibility_ratio_dict, exec_time_dict = {}, {}, {}, {}, {}, {}
        for ioi_idx in ioi_dict.keys():
            ioi = ioi_dict[ioi_idx]['ioi']
            ioi_label = ioi_dict[ioi_idx]['label']
            ioi_exec_time = ioi_dict[ioi_idx]['time']
            processed_perturbations = ioi_dict[ioi_idx]['proc_perturbations']
            perturbations_labels = ioi_dict[ioi_idx]['perturbations_label']
            perturbations_weights = ioi_dict[ioi_idx]['perturbations_weights']
            lin_model = RidgeClassifier(alpha=self.regul)
            lin_model.fit(processed_perturbations,perturbations_labels,sample_weight=perturbations_weights.reshape(perturbations_labels.shape))
            accuracy = self.coefficient_accuracy(data_obj, lin_model, ioi)
            fidelity_ratio = self.fidelity(lin_model, processed_perturbations, perturbations_labels)
            feat_robustness = self.robustness(perturbator_obj, data_obj, ioi, ioi_label)
            feasibility_ratio = self.feasibility(processed_perturbations)
            lin_model_dict[ioi_idx] = lin_model
            accuracy_dict[ioi_idx] = accuracy
            fidelity_ratio_dict[ioi_idx] = fidelity_ratio
            feat_robustness_dict[ioi_idx] = feat_robustness
            feasibility_ratio_dict[ioi_idx] = feasibility_ratio
            exec_time_dict[ioi_idx] = ioi_exec_time
        return lin_model_dict, accuracy_dict, fidelity_ratio_dict, feat_robustness_dict, feasibility_ratio_dict, exec_time_dict